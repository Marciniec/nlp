{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution of https://github.com/apohllo/nlp/blob/master/9-ner.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly select 100 bills.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp `ls | shuf -n 100` random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognize the named entities in the documents using the n82 model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: random/1998_593.txt\n",
      "Processing: random/2003_151.txt\n",
      "Processing: random/1997_674.txt\n",
      "Processing: random/1997_751.txt\n",
      "Processing: random/2004_577.txt\n",
      "Processing: random/2003_1610.txt\n",
      "Processing: random/1997_781.txt\n",
      "Processing: random/2000_1100.txt\n",
      "Processing: random/2004_146.txt\n",
      "Processing: random/2004_630.txt\n",
      "Processing: random/1997_676.txt\n",
      "Processing: random/1995_480.txt\n",
      "Processing: random/2000_1322.txt\n",
      "Processing: random/1998_1115.txt\n",
      "Processing: random/2001_246.txt\n",
      "Processing: random/2000_1324.txt\n",
      "Processing: random/1996_42.txt\n",
      "Processing: random/2000_839.txt\n",
      "Processing: random/1997_739.txt\n",
      "Processing: random/2004_1845.txt\n",
      "Processing: random/2004_2249.txt\n",
      "Processing: random/2003_1068.txt\n",
      "Processing: random/1994_591.txt\n",
      "Processing: random/1997_506.txt\n",
      "Processing: random/2004_627.txt\n",
      "Processing: random/1999_802.txt\n",
      "Processing: random/2004_2772.txt\n",
      "Processing: random/1997_470.txt\n",
      "Processing: random/2000_546.txt\n",
      "Processing: random/1997_272.txt\n",
      "Processing: random/2000_179.txt\n",
      "Processing: random/2004_148.txt\n",
      "Processing: random/1996_41.txt\n",
      "Processing: random/2003_718.txt\n",
      "Processing: random/1997_882.txt\n",
      "Processing: random/1996_459.txt\n",
      "Processing: random/2001_908.txt\n",
      "Processing: random/1997_97.txt\n",
      "Processing: random/2004_1807.txt\n",
      "Processing: random/1997_630.txt\n",
      "Processing: random/2004_1962.txt\n",
      "Processing: random/2001_84.txt\n",
      "Processing: random/2001_1229.txt\n",
      "Processing: random/1997_741.txt\n",
      "Processing: random/1995_152.txt\n",
      "Processing: random/2004_2619.txt\n",
      "Processing: random/2002_1204.txt\n",
      "Processing: random/2000_1251.txt\n",
      "Processing: random/1997_736.txt\n",
      "Processing: random/2003_1693.txt\n",
      "Processing: random/1995_60.txt\n",
      "Processing: random/2004_1644.txt\n",
      "Processing: random/1997_592.txt\n",
      "Processing: random/1998_931.txt\n",
      "Processing: random/1996_176.txt\n",
      "Processing: random/2001_786.txt\n",
      "Processing: random/2004_1925.txt\n",
      "Processing: random/2001_761.txt\n",
      "Processing: random/2003_1850.txt\n",
      "Processing: random/2001_1371.txt\n",
      "Processing: random/2001_1452.txt\n",
      "Processing: random/2000_549.txt\n",
      "Processing: random/1997_491.txt\n",
      "Processing: random/2000_383.txt\n",
      "Processing: random/2001_1066.txt\n",
      "Processing: random/2004_1533.txt\n",
      "Processing: random/2001_1407.txt\n",
      "Processing: random/1996_687.txt\n",
      "Processing: random/2000_239.txt\n",
      "Processing: random/1999_728.txt\n",
      "Processing: random/2001_1118.txt\n",
      "Processing: random/2001_1403.txt\n",
      "Processing: random/1997_691.txt\n",
      "Processing: random/1999_686.txt\n",
      "Processing: random/2003_153.txt\n",
      "Processing: random/2003_2262.txt\n",
      "Processing: random/1997_688.txt\n",
      "Processing: random/2001_1116.txt\n",
      "Processing: random/2004_1532.txt\n",
      "Processing: random/1996_43.txt\n",
      "Processing: random/2001_498.txt\n",
      "Processing: random/1996_493.txt\n",
      "Processing: random/2001_764.txt\n",
      "Processing: random/1998_471.txt\n",
      "Processing: random/1993_599.txt\n",
      "Processing: random/1997_770.txt\n",
      "Processing: random/1994_669.txt\n",
      "Processing: random/1995_792.txt\n",
      "Processing: random/2000_1310.txt\n",
      "Processing: random/1994_602.txt\n",
      "Processing: random/2001_459.txt\n",
      "Processing: random/1997_715.txt\n",
      "Processing: random/2001_1323.txt\n",
      "Processing: random/2004_94.txt\n",
      "Processing: random/2000_1028.txt\n",
      "Processing: random/2003_1692.txt\n",
      "Processing: random/1997_467.txt\n",
      "Processing: random/2004_2782.txt\n",
      "Processing: random/1998_1019.txt\n",
      "Processing: random/2000_1166.txt\n",
      "GLOBAL 4201.11048007 seconds ---\n"
     ]
    }
   ],
   "source": [
    "!python ner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xmls(directory_path):\n",
    "    xml_dicts = []\n",
    "    files = [file for file in listdir(directory_path) if isfile(join(directory_path, file))]\n",
    "    for file in files:\n",
    "        with open(f\"{directory_path}/{file}\") as input_file:\n",
    "            xml_dict = xmltodict.parse(input_file.read())\n",
    "            xml_dicts.append(xml_dict)  \n",
    "    return xml_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the frequency of the recognized classes:\n",
    "    * fine-grained classification histogram (classes such as nam_fac_bridge, nam_liv_animal).\n",
    "    * coarse-grained classification histogram (classes such as nam_adj, nam_eve, nam_fac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
