{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "from fastai.text import *\n",
    "from torch.utils.data.dataset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "WGTS_PATH = './v50knl4/work/up_low50k/models/fwd_v50k_finetune_lm_enc.h5'\n",
    "SP_MODEL_PATH = './v50knl4/work/up_low50k/tmp/sp-50k.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(SP_MODEL_PATH)\n",
    "\n",
    "sp.SetEncodeExtraOptions(\"bos:eos\")\n",
    "sp.SetDecodeExtraOptions(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt=5\n",
    "vs = len(sp)\n",
    "em_sz,nh,nl = 400 ,1150,4\n",
    "max_seq = 1000000\n",
    "pad_token = 1\n",
    "bidir = False\n",
    "qrnn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = MultiBatchRNN(bptt, max_seq, vs, em_sz, nh, nl, pad_token,\n",
    "                    bidir, qrnn)\n",
    "\n",
    "model = SequentialRNN(rnn, LinearDecoder(vs, em_sz, 0, tie_encoder=rnn.encoder))\n",
    "\n",
    "load_model(model[0], WGTS_PATH)\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(50000, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(50000, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (3): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout()\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout()\n",
       "      (1): LockedDropout()\n",
       "      (2): LockedDropout()\n",
       "      (3): LockedDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=50000, bias=False)\n",
       "    (dropout): LockedDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "        self.x = x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.x[idx]\n",
    "        return sentence[:-1], sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence): \n",
    "    ids = [np.array(sp.encode_as_ids(sentence))]\n",
    "\n",
    "    dataset = TextDataset(ids)\n",
    "    sampler = SortSampler(ids, key=lambda x: len(ids[x]))\n",
    "    dl = DataLoader(dataset, batch_size=100, transpose=True, pad_idx=1, sampler=sampler, pre_pad=False)\n",
    "\n",
    "    tensors = None\n",
    "    with no_grad_context():\n",
    "        for (x, y) in dl:\n",
    "            tensors, _, _ = model(x)\n",
    "            \n",
    "    last_tensor = tensors[-1]\n",
    "\n",
    "    best = int(torch.multinomial(tensors[-1].exp(), 1))\n",
    "    word = sp.decode_ids([best])\n",
    "    \n",
    "    while best in ids[0] or not word.isalpha():\n",
    "        last_tensor[best] = -1\n",
    "        best = int(torch.argmax(last_tensor))\n",
    "        word = sp.decode_ids([best])\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(sentence, length):\n",
    "    result = sentence\n",
    "    res_list = []\n",
    "    \n",
    "    for i in range(length):\n",
    "        word = predict(result)\n",
    "        if len(word) > 0 and word[0].isalpha() and (len(word) > 2 or word.lower() in ['a', 'o', 'i', 'w', 'z']):\n",
    "            result += (\" \" + word)\n",
    "            res_list.append(word)\n",
    "        else:\n",
    "            result += word\n",
    "            res_list.append(word)\n",
    "    return result, res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Warszawa to największe\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(M)Warszawa to największe miasto na znajdującym się w pobliżu centrum miasta i Hawan a także Chin a konkretnie Marsa oraz Burund i Glasgow z prawosławnych miast o\n"
     ]
    }
   ],
   "source": [
    "print(f\"(M){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Te zabawki należą do\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(D)Te zabawki należą do bardzo podobnych w tym temacie i zachęcają dzieci na bezpłatną wycieczkę po całym\n"
     ]
    }
   ],
   "source": [
    "print(f\"(D){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Policjant przygląda się\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Policjant przygląda się prze kazaniu hipnozy adapt ującego trolejbusow ron dzie sl źc w to Pensjonat Monroe'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"(C){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Na środku skrzyżowania widać\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Na środku skrzyżowania widać ślady planowania pracy zobowiąza lności za umiejętność klasyfikowani a refleksyjn ość daje równe szanse'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"(B){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Właściciel samochodu widział złodzieja z\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N)Właściciel samochodu widział złodzieja z ograniczonym i przetwórcą wymagane identyfikatory ją Paweł używając Res ety ka średnio on\n"
     ]
    }
   ],
   "source": [
    "print(f\"(N){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Prezydent z premierem rozmawiali wczoraj o\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ms)Prezydent z premierem rozmawiali wczoraj o potrzebie remontu zaplecza techniczn ego obejmującym szpitale kliniczne i kasy chorych NFZ w ramach konkursu\n"
     ]
    }
   ],
   "source": [
    "print(f\"(Ms){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(\"Witaj drogi\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(W)Witaj drogi Cesarz zadawał sut o ctl wyzwaniu i paragraf więzi eń przesłany przez\n"
     ]
    }
   ],
   "source": [
    "print(f\"(W){r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_sentence_male = \"Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie\"\n",
    "gender_sentence_female = \"Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(gender_sentence_male, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MALE) Gdybym wiedział wtedy dokładnie to co wiem teraz, to bym się nie wypłacił a ja podejrzewam w ostateczności jaki zadziałał termin na otwieranie tego przedłużenie i jak dodał em proto nadania z niego do stając ego\n"
     ]
    }
   ],
   "source": [
    "print(f\"(MALE) {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(gender_sentence_female, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FEMALE) Gdybym wiedziała wtedy dokładnie to co wiem teraz, to bym się nie stres owała plus wąwoz wyeksportowa ła giew od ego Lo ody top work i zielonego ot uchy li che de la gol czworobok darmowe\n"
     ]
    }
   ],
   "source": [
    "print(f\"(FEMALE) {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = \"Polscy naukowcy odkryli w Tatrach nowy gatunek istoty żywej. Zwięrzę to przypomina małpę, lecz porusza się na dwóch nogach i potrafi posługiwać się narzędziami. Przy dłuższej obserwacji okazało się, że potrafi również posługiwać się językiem polskim, a konkretnie gwarą podhalańską. Zwierzę to zostało nazwane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "r, rl = predict_sentence(long, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Polscy naukowcy odkryli w Tatrach nowy gatunek istoty żywej. Zwięrzę to przypomina małpę, lecz porusza się na dwóch nogach i potrafi posługiwać się narzędziami. Przy dłuższej obserwacji okazało się, że potrafi również posługiwać się językiem polskim, a konkretnie gwarą podhalańską. Zwierzę to zostało nazwane brazylijskim psem biodrowym z plemieni a pole golfowe swepy pieniedz a zwołac sklad ających konido posaż a tylko tujemy opuszczani petentie nauczycielski ego nosc Podkarpacia Trening ową Odzież Boże Groźn czkądoch a seans zdobywani a wybici a nie lekarstw o dejmowanie'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
